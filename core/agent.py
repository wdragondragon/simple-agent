import json
import time
from datetime import timedelta

from core.parser import parse_action
from core.prompt import SYSTEM_PROMPT
from core.state import State
from llm.client import call_llm_with_tools
from tools.ConceptMemory import ConceptMemory
from tools.Memory import Memory
from tools.compressor import compress_memory
from tools.registry import TOOLS
from tools.schemas import TOOL_SCHEMAS


class Agent:
    def __init__(self, client, model):
        self.client = client
        self.model = model
        self.memory = Memory()
        self.concept_memory = ConceptMemory()

    def run(self, goal, max_steps=100):
        state = State.INIT

        step = 0
        last_action = None
        self.last_tool_calls = []
        result_msg = None
        start_time = time.perf_counter()
        while True:
            step += 1
            print(f"\n====== STEP {step} | STATE: {state.name} ======")

            # ===== THINK =====
            if state in (State.INIT, State.THINK):
                self.maybe_compress()
                messages = [
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": f"ç›®æ ‡ï¼š{goal}"}
                ]
                messages += self.concept_memory.dump()
                messages += self.memory.dump()
                print("è¯¢é—®ï¼š" + str(messages))
                assistant_msg = call_llm_with_tools(self.client, self.model, messages, tools=TOOL_SCHEMAS)
                print("å›ç­”ï¼š" + str(assistant_msg))

                # å°†assistantçš„æ¶ˆæ¯æ·»åŠ åˆ°å†…å­˜ï¼ˆå¯èƒ½æ˜¯contentæˆ–tool_callsï¼‰
                msg_dict = {"role": "assistant"}
                if assistant_msg.content is not None:
                    msg_dict["content"] = assistant_msg.content
                if assistant_msg.tool_calls is not None:
                    # å°†tool_callsè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                    try:
                        # å°è¯•ä½¿ç”¨ model_dump() (Pydantic v2) æˆ– dict() (Pydantic v1)
                        if hasattr(assistant_msg.tool_calls[0], 'model_dump'):
                            msg_dict["tool_calls"] = [tc.model_dump() for tc in assistant_msg.tool_calls]
                        else:
                            msg_dict["tool_calls"] = [tc.dict() for tc in assistant_msg.tool_calls]
                    except (AttributeError, IndexError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·
                        msg_dict["tool_calls"] = assistant_msg.tool_calls
                self.memory.add_message(msg_dict)

                if assistant_msg.tool_calls:
                    # æœ‰tool callsï¼Œè¿›å…¥ACTçŠ¶æ€æ‰§è¡Œ
                    self.last_tool_calls = assistant_msg.tool_calls
                    state = State.ACT
                else:
                    # æ²¡æœ‰tool callsï¼Œæ£€æŸ¥æ˜¯å¦æœ‰contentä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
                    if assistant_msg.content:
                        # å°†contentä½œä¸ºæœ€ç»ˆç­”æ¡ˆï¼ˆå‡è®¾æ¨¡å‹ç›´æ¥è¾“å‡ºç­”æ¡ˆï¼‰
                        result_msg = assistant_msg.content
                        state = State.FINISH
                    else:
                        # æ—¢æ— tool callsä¹Ÿæ— contentï¼Œé”™è¯¯
                        self.memory.add("user", "ERROR: LLM returned empty response")
                        continue

            # ===== ACT =====
            elif state == State.ACT:
                # æ‰§è¡Œæ¯ä¸ªtool call
                for tool_call in self.last_tool_calls:
                    func_name = tool_call.function.name
                    try:
                        func_args = json.loads(tool_call.function.arguments)
                    except json.JSONDecodeError as e:
                        observation = f"ERROR: å‚æ•°è§£æå¤±è´¥: {e}"
                        self.memory.add_message({
                            "role": "tool",
                            "content": observation,
                            "tool_call_id": tool_call.id
                        })
                        continue

                    if func_name not in TOOLS:
                        observation = f"ERROR: æœªçŸ¥å·¥å…· {func_name}"
                    else:
                        print(f"æ­£åœ¨è°ƒç”¨å·¥å…·[{func_name}]ï¼Œå…¥å‚:{func_args}")
                        observation = TOOLS[func_name](**func_args)

                    print("æˆ‘è®¡ç®—çš„Observation:", observation)
                    # æ·»åŠ toolæ¶ˆæ¯
                    self.memory.add_message({
                        "role": "tool",
                        "content": str(observation),
                        "tool_call_id": tool_call.id
                    })

                    if func_name == "finish":
                        result_msg = observation
                        state = State.FINISH
                        break  # ä¸å†æ‰§è¡Œåç»­tool calls
                
                if state != State.FINISH:
                    state = State.OBSERVE

            # ===== OBSERVE =====
            elif state == State.OBSERVE:
                state = State.THINK

            # ===== FINISH =====
            elif state == State.FINISH:

                print("\nğŸ‰ Agent æ­£å¸¸ç»“æŸ")
                break

        return {"step": step, "cost_time": str(timedelta(seconds=time.perf_counter() - start_time)),
                "result": result_msg}

    def maybe_compress(self):
        if len(self.memory.messages) < 100:
            return

        messages = self.concept_memory.dump()
        messages += self.memory.dump()
        concepts = compress_memory(self.model, messages)
        self.concept_memory.add(concepts)
        self.memory.clear()
